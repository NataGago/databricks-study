{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a36cfa73-aed5-4d71-aab8-2d7fc07801b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# DLT pipeline log analysis\n",
    "\n",
    "<img style=\"float:right\" width=\"500\" src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/dlt/dlt-loans-dashboard.png?raw=true\">\n",
    "\n",
    "Each DLT Pipeline can be configured to save out the metrics to a table in Unity Catalog. From this table we can see what is happening and the quality of the data passing through it.\n",
    "\n",
    "You can leverage the expecations directly as a SQL table with Databricks SQL to track your expectation metrics and send alerts as required. \n",
    "\n",
    "This notebook extracts and analyses expectation metrics to build such KPIS.\n",
    "\n",
    "## Your event log table is now available as a Table within your schema!\n",
    "\n",
    "This is simply set as an option in your DLT configuration menu.\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=364952466732164&notebook=%2F03-Log-Analysis&demo_name=dlt-loans&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fdlt-loans%2F03-Log-Analysis&version=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ca7818d-3fdb-449d-a566-21f0c2019e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM main.dbdemos_dlt_loan.event_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaaff08c-2b74-4cee-af72-6763f51db79e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Note: old legacy way to access your event log is through tthe event_log function:\n",
    "-- CREATE OR REPLACE TEMPORARY VIEW demo_dlt_loans_system_event_log_raw \n",
    "--   as SELECT * FROM event_log(TABLE(main.dbdemos_dlt_loan.raw_txs));\n",
    "-- SELECT * FROM demo_dlt_loans_system_event_log_raw order by timestamp desc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84e1404f-012c-47ce-afe7-c8e7bf3c14b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The `details` column contains metadata about each Event sent to the Event Log in a JSON blob. Using `parse_json` and the `VARIANT` data type we can explore it as if it was an object. There are different fields depending on what type of Event it is. Some examples include:\n",
    "* `user_action` Events occur when taking actions like creating the pipeline\n",
    "* `flow_definition` Events occur when a pipeline is deployed or updated and have lineage, schema, and execution plan information\n",
    "  * `output_dataset` and `input_datasets` - output table/view and its upstream table(s)/view(s)\n",
    "  * `flow_type` - whether this is a complete or append flow\n",
    "  * `explain_text` - the Spark explain plan\n",
    "* `flow_progress` Events occur when a data flow starts running or finishes processing a batch of data\n",
    "  * `metrics` - currently contains `num_output_rows`\n",
    "  * `data_quality` - contains an array of the results of the data quality rules for this particular dataset\n",
    "    * `dropped_records`\n",
    "    * `expectations`\n",
    "      * `name`, `dataset`, `passed_records`, `failed_records`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b7b686a-d459-42a0-957e-3df0eb3d6f41",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Lineage Information"
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  details:flow_definition.output_dataset,\n",
    "  details:flow_definition.input_datasets,\n",
    "  details:flow_definition.flow_type,\n",
    "  details:flow_definition.schema,\n",
    "  details:flow_definition\n",
    "FROM main.dbdemos_dlt_loan.event_logs\n",
    "WHERE details:flow_definition IS NOT NULL\n",
    "ORDER BY timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4650dce-764e-47a8-bbe2-56154b3928a6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Quality Results"
    }
   },
   "outputs": [],
   "source": [
    "select\n",
    "  e.origin.update_id,\n",
    "  ex.value:name::string,\n",
    "  ex.value:dataset::string,\n",
    "  ex.value:passed_records::long as passed_records,\n",
    "  ex.value:failed_records::long as failed_records\n",
    "from\n",
    "  main.dbdemos_dlt_loan.event_logs e,\n",
    "  lateral variant_explode(parse_json(e.details:flow_progress:data_quality:expectations:[ * ])) as ex\n",
    "where\n",
    "  e.event_type = \"flow_progress\"\n",
    "  and details:flow_progress:status = \"RUNNING\"\n",
    "  and details:flow_progress:data_quality:expectations IS NOT NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c83fb94-eae5-4399-9566-00b2f1d6a54f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Your expectations are ready to be queried in SQL! Open the <a dbdemos-dashboard-id=\"dlt-expectations\" href='/sql/dashboardsv3/01f024936ce51a0e863f31dff9288761' target=\"_blank\">data Quality Dashboard example</a> for more details."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03-Log-Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
